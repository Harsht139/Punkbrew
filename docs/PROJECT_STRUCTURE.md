# ğŸº Punk Brewery Data Pipeline - Project Structure

## Overview
This document provides a comprehensive overview of the project structure and explains the purpose of each component in the Punk Brewery Data Pipeline.

## Directory Structure

```
data_pipeline/
â”œâ”€â”€ ğŸ“ src/                     # Source code
â”‚   â”œâ”€â”€ ğŸ“ extract/            # Data extraction modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ punk_api_extractor.py
â”‚   â”œâ”€â”€ ğŸ“ transform/          # Data transformation modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ beer_transformer.py
â”‚   â”œâ”€â”€ ğŸ“ load/               # Data loading modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ bigquery_loader.py
â”‚   â”œâ”€â”€ ğŸ“ utils/              # Utility modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config_manager.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py                # Main entry point
â”œâ”€â”€ ğŸ“ config/                 # Configuration files
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ ğŸ“ tests/                  # Unit and integration tests
â”‚   â””â”€â”€ test_extractor.py
â”œâ”€â”€ ğŸ“ dbt/                    # dbt models and transformations
â”‚   â”œâ”€â”€ ğŸ“ models/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ staging/
â”‚   â”‚   â”‚   â”œâ”€â”€ sources.yml
â”‚   â”‚   â”‚   â””â”€â”€ stg_beers.sql
â”‚   â”‚   â””â”€â”€ ğŸ“ marts/
â”‚   â”‚       â””â”€â”€ ğŸ“ core/
â”‚   â”‚           â”œâ”€â”€ dim_beer_categories.sql
â”‚   â”‚           â””â”€â”€ fact_beer_analytics.sql
â”‚   â”œâ”€â”€ ğŸ“ macros/
â”‚   â”œâ”€â”€ ğŸ“ seeds/
â”‚   â”œâ”€â”€ ğŸ“ snapshots/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â””â”€â”€ profiles.yml
â”œâ”€â”€ ğŸ“ airflow/                # Airflow DAGs and plugins
â”‚   â”œâ”€â”€ ğŸ“ dags/
â”‚   â”‚   â””â”€â”€ punk_brewery_pipeline_dag.py
â”‚   â””â”€â”€ ğŸ“ plugins/
â”œâ”€â”€ ğŸ“ docker/                 # Docker configurations
â”œâ”€â”€ ğŸ“ sql/                    # SQL scripts and schemas
â”‚   â”œâ”€â”€ ğŸ“ schemas/
â”‚   â”‚   â””â”€â”€ bigquery_schema.sql
â”‚   â””â”€â”€ ğŸ“ queries/
â”œâ”€â”€ ğŸ“ docs/                   # Documentation
â”‚   â””â”€â”€ PROJECT_STRUCTURE.md
â”œâ”€â”€ ğŸ“ scripts/                # Deployment and utility scripts
â”‚   â””â”€â”€ setup.sh
â”œâ”€â”€ ğŸ“ notebooks/              # Jupyter notebooks for exploration
â”œâ”€â”€ ğŸ“„ requirements.txt        # Python dependencies
â”œâ”€â”€ ğŸ“„ Dockerfile             # Docker image definition
â”œâ”€â”€ ğŸ“„ docker-compose.yml     # Docker Compose configuration
â”œâ”€â”€ ğŸ“„ Makefile               # Development commands
â”œâ”€â”€ ğŸ“„ .env.example           # Environment variables template
â”œâ”€â”€ ğŸ“„ .gitignore             # Git ignore rules
â””â”€â”€ ğŸ“„ README.md              # Project documentation
```

## Component Details

### ğŸ”§ Core Application (`src/`)

#### **Main Entry Point**
- `main.py` - Orchestrates the entire pipeline execution
- Provides CLI interface with different execution modes
- Handles error management and logging

#### **Extract Module (`extract/`)**
- `punk_api_extractor.py` - Handles data extraction from Punk API
- Features:
  - Asynchronous HTTP requests for performance
  - Rate limiting and retry logic
  - Incremental data loading support
  - Error handling and metrics collection

#### **Transform Module (`transform/`)**
- `beer_transformer.py` - Transforms and categorizes raw beer data
- Features:
  - Beer categorization based on yeast types and styles
  - Data cleaning and validation
  - Ingredient parsing and standardization
  - Business logic implementation

#### **Load Module (`load/`)**
- `bigquery_loader.py` - Loads data into BigQuery
- Features:
  - Staging through Cloud Storage
  - Incremental loading with merge operations
  - Schema management and validation
  - Data quality checks

#### **Utilities (`utils/`)**
- `config_manager.py` - Configuration management
- `logger.py` - Centralized logging setup

### ğŸ“Š Data Transformation (`dbt/`)

#### **Models Structure**
- **Staging Models** (`models/staging/`)
  - `stg_beers.sql` - Cleans and standardizes raw data
  - `sources.yml` - Defines data sources and tests

- **Marts Models** (`models/marts/core/`)
  - `dim_beer_categories.sql` - Beer category dimension table
  - `fact_beer_analytics.sql` - Main analytical fact table

#### **Configuration**
- `dbt_project.yml` - dbt project configuration
- `profiles.yml` - Database connection profiles

### ğŸ”„ Orchestration (`airflow/`)

#### **DAGs**
- `punk_brewery_pipeline_dag.py` - Main pipeline orchestration
- Features:
  - Daily scheduling
  - Task dependencies
  - Error handling and retries
  - Data quality checks

### ğŸ—„ï¸ Database Schema (`sql/`)

#### **Schema Definitions**
- `bigquery_schema.sql` - Complete BigQuery schema
- Includes:
  - Staging tables
  - Dimension tables
  - Fact tables
  - Analytical views

### ğŸ§ª Testing (`tests/`)

#### **Test Structure**
- `test_extractor.py` - Unit tests for API extraction
- Covers:
  - API interaction testing
  - Error handling validation
  - Data format verification

### ğŸ³ Containerization

#### **Docker Configuration**
- `Dockerfile` - Application container definition
- `docker-compose.yml` - Multi-service orchestration
- Features:
  - Production-ready container
  - Development environment setup
  - Optional monitoring services

### âš™ï¸ Configuration & Setup

#### **Configuration Files**
- `config/config.yaml` - Application configuration
- `.env.example` - Environment variables template
- `requirements.txt` - Python dependencies

#### **Development Tools**
- `Makefile` - Development commands and shortcuts
- `scripts/setup.sh` - Automated environment setup
- `.gitignore` - Version control exclusions

## Data Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Punk API      â”‚â”€â”€â”€â–¶â”‚  Cloud Storage   â”‚â”€â”€â”€â–¶â”‚   BigQuery      â”‚
â”‚                 â”‚    â”‚   (Staging)      â”‚    â”‚ (Data Warehouse)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚   DataStudio    â”‚
                                               â”‚   Dashboard     â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Features

### ğŸš€ **Performance & Scalability**
- Asynchronous data extraction
- Partitioned and clustered BigQuery tables
- Incremental data processing
- Containerized deployment

### ğŸ” **Data Quality**
- Comprehensive data validation
- dbt tests and documentation
- Error handling and monitoring
- Data lineage tracking

### ğŸ“ˆ **Analytics Ready**
- Pre-built analytical views
- Beer categorization logic
- Trend analysis capabilities
- Dashboard-optimized data models

### ğŸ› ï¸ **Developer Experience**
- Comprehensive testing suite
- Automated setup scripts
- Clear documentation
- Makefile for common tasks

## Getting Started

1. **Setup Environment**
   ```bash
   make setup
   ```

2. **Configure Credentials**
   ```bash
   cp .env.example .env
   # Edit .env with your GCP credentials
   ```

3. **Run Tests**
   ```bash
   make test
   ```

4. **Execute Pipeline**
   ```bash
   make run-pipeline
   ```

## Next Steps

- Set up Google Cloud Platform credentials
- Configure BigQuery datasets
- Deploy Airflow for scheduling
- Create DataStudio dashboards
- Set up monitoring and alerting
